import json
import os

# Create notebooks directory if it doesn't exist
os.makedirs('notebooks', exist_ok=True)

# Notebook content
notebook = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Enhanced Patient Clustering Analysis - MedOptix Treatment Data\n",
                "\n",
                "This notebook performs an in-depth analysis of patient clusters based on treatment outcomes, adherence patterns, and satisfaction levels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "from scipy import stats\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.metrics import silhouette_score\n",
                "from statsmodels.stats.multicomp import MultiComparison\n",
                "\n",
                "# Set style for better visualizations\n",
                "plt.style.use('seaborn')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "# Read the merged dataset\n",
                "df = pd.read_csv('../data/processed/cleaned_merged_medoptix.csv')\n",
                "\n",
                "# Convert date columns\n",
                "date_cols = ['signup_date', 'sent_at', 'date']\n",
                "for col in date_cols:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_datetime(df[col])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enhanced Patient Clustering Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Calculate enhanced patient-level metrics for clustering\n",
                "patient_metrics = df.groupby('patient_id').agg({\n",
                "    # Pain metrics\n",
                "    'pain_level': ['mean', 'std', lambda x: x.iloc[-1] - x.iloc[0], \n",
                "                  lambda x: (x.iloc[-1] - x.iloc[0])/len(x)],  # pain change rate\n",
                "    \n",
                "    # Adherence metrics\n",
                "    'home_adherence_pc': ['mean', 'std', 'min', 'max',\n",
                "                         lambda x: (x.iloc[-1] - x.iloc[0])/len(x)],  # adherence trend\n",
                "    \n",
                "    # Satisfaction metrics\n",
                "    'satisfaction': ['mean', 'std', 'min', 'max'],\n",
                "    \n",
                "    # Treatment metrics\n",
                "    'session_id': 'count',\n",
                "    'date': [lambda x: (x.max() - x.min()).days,  # treatment duration\n",
                "            lambda x: len(x)/max((x.max() - x.min()).days, 1)],  # session frequency\n",
                "    \n",
                "    # Demographic metrics\n",
                "    'age': 'first',\n",
                "    'bmi': 'first',\n",
                "    'gender': 'first',\n",
                "    'chronic_cond': 'first',\n",
                "    'injury_type': 'first'\n",
                "}).reset_index()\n",
                "\n",
                "# Flatten column names\n",
                "patient_metrics.columns = ['_'.join(col).strip('_') for col in patient_metrics.columns.values]\n",
                "\n",
                "# Rename columns for clarity\n",
                "column_mapping = {\n",
                "    'patient_id': 'patient_id',\n",
                "    'pain_level_mean': 'avg_pain',\n",
                "    'pain_level_std': 'pain_volatility',\n",
                "    'pain_level_<lambda_0>': 'pain_change',\n",
                "    'pain_level_<lambda_1>': 'pain_change_rate',\n",
                "    'home_adherence_pc_mean': 'avg_adherence',\n",
                "    'home_adherence_pc_std': 'adherence_volatility',\n",
                "    'home_adherence_pc_min': 'min_adherence',\n",
                "    'home_adherence_pc_max': 'max_adherence',\n",
                "    'home_adherence_pc_<lambda_0>': 'adherence_trend',\n",
                "    'satisfaction_mean': 'avg_satisfaction',\n",
                "    'satisfaction_std': 'satisfaction_volatility',\n",
                "    'satisfaction_min': 'min_satisfaction',\n",
                "    'satisfaction_max': 'max_satisfaction',\n",
                "    'session_id_count': 'session_count',\n",
                "    'date_<lambda_0>': 'treatment_duration',\n",
                "    'date_<lambda_1>': 'session_frequency',\n",
                "    'age_first': 'age',\n",
                "    'bmi_first': 'bmi',\n",
                "    'gender_first': 'gender',\n",
                "    'chronic_cond_first': 'chronic_cond',\n",
                "    'injury_type_first': 'injury_type'\n",
                "}\n",
                "patient_metrics = patient_metrics.rename(columns=column_mapping)\n",
                "\n",
                "# Select features for clustering\n",
                "cluster_features = [\n",
                "    'avg_pain', 'pain_change', 'pain_change_rate', 'pain_volatility',\n",
                "    'avg_adherence', 'adherence_trend', 'adherence_volatility',\n",
                "    'avg_satisfaction', 'satisfaction_volatility',\n",
                "    'session_frequency', 'treatment_duration'\n",
                "]\n",
                "\n",
                "# Handle missing values\n",
                "patient_metrics[cluster_features] = patient_metrics[cluster_features].fillna(patient_metrics[cluster_features].mean())\n",
                "\n",
                "# Scale the features\n",
                "scaler = StandardScaler()\n",
                "X = patient_metrics[cluster_features]\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "# PCA for dimensionality reduction and visualization\n",
                "pca = PCA(n_components=2)\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "\n",
                "# Find optimal number of clusters\n",
                "silhouette_scores = []\n",
                "K = range(2, 8)\n",
                "for k in K:\n",
                "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
                "    kmeans.fit(X_scaled)\n",
                "    score = silhouette_score(X_scaled, kmeans.labels_)\n",
                "    silhouette_scores.append(score)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(K, silhouette_scores, 'bo-')\n",
                "plt.xlabel('Number of Clusters (k)')\n",
                "plt.ylabel('Silhouette Score')\n",
                "plt.title('Silhouette Score vs Number of Clusters')\n",
                "plt.show()\n",
                "\n",
                "# Perform KMeans clustering\n",
                "kmeans = KMeans(n_clusters=3, random_state=42)\n",
                "patient_metrics['cluster'] = kmeans.fit_predict(X_scaled)\n",
                "\n",
                "# Name the clusters\n",
                "cluster_names = {\n",
                "    0: 'Steady Progressors',\n",
                "    1: 'Fast Improvers',\n",
                "    2: 'Frustrated Droppers'\n",
                "}\n",
                "patient_metrics['cluster_name'] = patient_metrics['cluster'].map(cluster_names)\n",
                "\n",
                "# Visualize clusters in PCA space\n",
                "plt.figure(figsize=(12, 8))\n",
                "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
                "                     c=patient_metrics['cluster'], \n",
                "                     cmap='viridis',\n",
                "                     alpha=0.6)\n",
                "plt.title('Patient Clusters (PCA Visualization)')\n",
                "plt.xlabel('First Principal Component')\n",
                "plt.ylabel('Second Principal Component')\n",
                "plt.colorbar(scatter, label='Cluster')\n",
                "plt.show()\n",
                "\n",
                "# Statistical tests for cluster differences\n",
                "print(\"\\nStatistical Tests for Cluster Differences:\")\n",
                "for feature in cluster_features:\n",
                "    print(f\"\\n{feature}:\")\n",
                "    # ANOVA test\n",
                "    f_stat, p_val = stats.f_oneway(*[group[feature] for name, group in patient_metrics.groupby('cluster')])\n",
                "    print(f\"ANOVA F-statistic: {f_stat:.2f}, p-value: {p_val:.4f}\")\n",
                "    \n",
                "    # Post-hoc Tukey's HSD test\n",
                "    mc = MultiComparison(patient_metrics[feature], patient_metrics['cluster'])\n",
                "    result = mc.tukeyhsd()\n",
                "    print(\"\\nTukey's HSD Test:\")\n",
                "    print(result)\n",
                "\n",
                "# Create detailed cluster profiles\n",
                "cluster_profiles = patient_metrics.groupby('cluster')[cluster_features].agg(['mean', 'std'])\n",
                "cluster_profiles['size'] = patient_metrics.groupby('cluster').size()\n",
                "\n",
                "# Visualize cluster characteristics\n",
                "plt.figure(figsize=(15, 10))\n",
                "for i, feature in enumerate(cluster_features):\n",
                "    plt.subplot(4, 3, i+1)\n",
                "    sns.boxplot(x='cluster_name', y=feature, data=patient_metrics)\n",
                "    plt.title(feature)\n",
                "    plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Create radar chart for cluster profiles\n",
                "def radar_chart(cluster_profiles, cluster_names):\n",
                "    # Number of variables\n",
                "    categories = ['Avg Pain', 'Pain Change', 'Adherence', 'Satisfaction', 'Session Freq']\n",
                "    N = len(categories)\n",
                "    \n",
                "    # Compute angle for each axis\n",
                "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
                "    angles += angles[:1]\n",
                "    \n",
                "    # Initialize the figure\n",
                "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
                "    \n",
                "    # Draw one axis per variable and add labels\n",
                "    plt.xticks(angles[:-1], categories)\n",
                "    \n",
                "    # Draw ylabels\n",
                "    ax.set_rlabel_position(0)\n",
                "    plt.yticks([0.25, 0.5, 0.75], [\"0.25\", \"0.5\", \"0.75\"], color=\"grey\", size=8)\n",
                "    plt.ylim(0, 1)\n",
                "    \n",
                "    # Plot each cluster\n",
                "    for cluster in range(3):\n",
                "        values = [\n",
                "            cluster_profiles.loc[cluster, ('avg_pain', 'mean')] / 10,\n",
                "            (cluster_profiles.loc[cluster, ('pain_change', 'mean')] + 5) / 10,\n",
                "            cluster_profiles.loc[cluster, ('avg_adherence', 'mean')] / 100,\n",
                "            cluster_profiles.loc[cluster, ('avg_satisfaction', 'mean')] / 5,\n",
                "            cluster_profiles.loc[cluster, ('session_frequency', 'mean')] / 2\n",
                "        ]\n",
                "        values += values[:1]\n",
                "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=cluster_names[cluster])\n",
                "        ax.fill(angles, values, alpha=0.1)\n",
                "    \n",
                "    plt.legend(loc='upper right', bbox_to_anchor=(0.3, 0.3))\n",
                "    plt.title('Cluster Profiles Comparison')\n",
                "    plt.show()\n",
                "\n",
                "# Create radar chart\n",
                "radar_chart(cluster_profiles, cluster_names)\n",
                "\n",
                "# Print detailed cluster profiles\n",
                "print(\"\\nDetailed Cluster Profiles:\")\n",
                "for cluster in range(3):\n",
                "    print(f\"\\n{cluster_names[cluster]}:\")\n",
                "    print(f\"Size: {cluster_profiles.loc[cluster, 'size']} patients\")\n",
                "    for feature in cluster_features:\n",
                "        mean = cluster_profiles.loc[cluster, (feature, 'mean')]\n",
                "        std = cluster_profiles.loc[cluster, (feature, 'std')]\n",
                "        print(f\"{feature}: {mean:.2f} ± {std:.2f}\")\n",
                "\n",
                "# Save clustered data with all features\n",
                "patient_metrics.to_csv('../data/processed/patient_clusters_enhanced.csv', index=False)\n",
                "\n",
                "# Create correlation heatmap for cluster features\n",
                "plt.figure(figsize=(12, 10))\n",
                "correlation_matrix = patient_metrics[cluster_features].corr()\n",
                "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
                "plt.title('Feature Correlation Matrix')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

# Write the notebook to file
with open('notebooks/01_eda_visuals.ipynb', 'w', encoding='utf-8') as f:
    json.dump(notebook, f, indent=1) 